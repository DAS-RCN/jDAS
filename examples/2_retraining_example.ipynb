{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9a774dd-67cc-4c8d-8bcd-f92acf02fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Enable interactive plotting in Jupyter\n",
    "\n",
    "# For Jupyter notebooks\n",
    "# %matplotlib notebook\n",
    "\n",
    "# For Jupyter lab\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39153ed1-8cba-4ded-8b90-4a41c604e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c69f9037-e58c-4e2e-9bb3-829cda3348cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "\n",
    "cwd = os.getcwd()\n",
    "pardir = os.path.abspath(os.path.join(cwd, \"..\"))\n",
    "modeldir = os.path.abspath(os.path.join(pardir, \"models\"))\n",
    "\n",
    "if pardir not in sys.path:\n",
    "    sys.path.append(pardir)\n",
    "\n",
    "from jDAS import JDAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceddd2dc-0461-4201-8334-d66c56e904fd",
   "metadata": {},
   "source": [
    "# Goal of this tutorial\n",
    "\n",
    "The basic denoising tutorial (`basic_denoising_example.ipynb`) shows how to perform basic denoising with *jDAS*. The example data used in that tutorial are obtained during the same DAS experiment as the data that was used in the training of the model, and so no retraining is needed. In this tutorial, we are going to retrain the model to obtain better accuracy on \"new\" data. In practice, retraining the model is recommended in the following scenarios:\n",
    "\n",
    "1. A new experiment was conducted (e.g. in a different location, or with different interrogator settings like the gauge length or maximum sensing distance).\n",
    "2. The conditions during one experiment strongly vary. This can be the case when new noise sources are introduced (construction works on-land, microseismic noise, etc.), or when the signal-to-noise ratio significantly changes.\n",
    "3. One particular event of interest, such as a major earthquake, occurs. In this case the model can be trained in \"single-sample mode\": instead of training on a large data set and optimising the model parameters for a (potentially) wide data range, the training is done on a very specific data range. Consequently, the _jDAS_ model will try to achieve the best denoising performance for this specific data set, at the cost of generalisation.\n",
    "\n",
    "Note that multiple models can be trained for different conditions (e.g. nighttime/daytime, on-land and submarine segments of the cable, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ca5768-10cd-4f73-84dc-e9e7a9a57be3",
   "metadata": {},
   "source": [
    "# Step 1: Generate new data\n",
    "\n",
    "As a simple example, we will generate some synthetic data. Standard Gaussian noise is low-pass filtered in space and time to artificially create spatio-temporal correlations. This will be the ground truth. We then generate spatially incoherent noise with the same frequency characteristics by randomly shuffling the rows of the original data. The model input data will be a superposition of the ground truth and noise. Since the noise has the same frequency characteristics as the ground truth, bandpass filtering will not be able to remove the noise.\n",
    "\n",
    "The resulting (noisy) data will exhibit very different characteristics from the data on which the original model was trained. To see the importance of retraining the model, we will first denoise the new data with the default pretrained model. We will then retrain the model on the new data, and repeat the denoising operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c78ace1-0c0c-4683-b938-242c73c99fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation parameters (will be reused)\n",
    "imshow_kwargs = {\n",
    "    \"interpolation\": \"none\",\n",
    "    \"aspect\": \"auto\",\n",
    "    \"vmin\": -2,\n",
    "    \"vmax\": 2,\n",
    "}\n",
    "\n",
    "# Setting the random seed\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Number of DAS channels, number of time samples\n",
    "Nch, Nt = 500, 40 * 2048\n",
    "\n",
    "# Generate the ground truth by low-pass filtering Gaussian random noise\n",
    "data = rng.normal(size=(Nch, Nt))\n",
    "data = gaussian_filter(data, sigma=(5, 50))\n",
    "\n",
    "# Generate incoherent noise with the same frequency characteristics by\n",
    "# shuffling the ground truth data along the channel axis\n",
    "noise = data.copy()\n",
    "rng.shuffle(noise, axis=0)\n",
    "\n",
    "# Input data: ground truth + noise\n",
    "noisy_data = data + noise\n",
    "\n",
    "# Split the data 50-50 into a train and validation set.\n",
    "# The train/validation data are normalised\n",
    "Nsplit = int(0.5 * Nt)\n",
    "\n",
    "train_data = np.expand_dims(noisy_data[:, :Nsplit], axis=0)\n",
    "train_data = train_data / data.std()\n",
    "val_data = np.expand_dims(noisy_data[:, Nsplit:], axis=0)\n",
    "val_data = val_data / data.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761215ae-ee22-43e8-ac6d-5e6ce9ad8adc",
   "metadata": {},
   "source": [
    "To verify that everything is correct, we plot a subset of the data for visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3342736c-d128-477b-97c5-c0510f93ac94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea93b3bf90b43059ffef1b4d32fc8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_slice = slice(20_000, 30_000)\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(9, 4), constrained_layout=True, sharex=\"all\", sharey=\"all\")\n",
    "\n",
    "axes[0].imshow(data[:, t_slice] / data.std(), **imshow_kwargs)\n",
    "axes[0].set_title(\"Ground truth\")\n",
    "\n",
    "axes[1].imshow(noisy_data[:, t_slice] / data.std(), **imshow_kwargs)\n",
    "axes[1].set_title(\"Noisy data\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d221213-6570-42ee-8bb9-da491458d341",
   "metadata": {},
   "source": [
    "# Performance without retraining\n",
    "\n",
    "To check how well (or not) the standard pretrained model performs without additional retraining, we call the *jDAS* denoising routine without post-process filtering, and visualise the results. As expected, the model output bears hardly any resemblance to the input data and exhibits large boundary artifacts (recall that the data are split into 2048-sized chunks in time when passed to the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb7af55e-1cfa-4fa2-9724-f765c07989da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 / 40\n",
      "Processing 5 / 40\n",
      "Processing 9 / 40\n",
      "Processing 13 / 40\n",
      "Processing 17 / 40\n",
      "Processing 21 / 40\n",
      "Processing 25 / 40\n",
      "Processing 29 / 40\n",
      "Processing 33 / 40\n",
      "Processing 37 / 40\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "jdas = JDAS()\n",
    "model = jdas.load_model()\n",
    "pre_train = jdas.denoise(noisy_data)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12e098be-4ca0-4747-a865-e0259932d645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2864f513dd4614a7bd2628efcd24a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_slice = slice(20_000, 30_000)\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(9, 4), constrained_layout=True, sharex=\"all\", sharey=\"all\")\n",
    "\n",
    "axes[0].imshow(data[:, t_slice] / data.std(), **imshow_kwargs)\n",
    "axes[0].set_title(\"Ground truth\")\n",
    "axes[1].imshow(pre_train[:, t_slice] / data.std(), **imshow_kwargs)\n",
    "axes[1].set_title(\"Reconstruction (before retraining)\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c90fbf-d81a-4b2e-94bc-583cc9a3244e",
   "metadata": {},
   "source": [
    "# Data loader and callbacks\n",
    "\n",
    "To prepare the retraining phase, we need to pass the training and validation data to a data loader. This data loader automatically creates mini-batches of randomly selected windows of data, with additional augmentations (polarity flip, time/space reversals). The `batch_size` is a user parameter that controls how many random samples are created per mini-batch. A smaller value will consume less memory, but will suffer from more stochastic noise during the gradient-descent optimisation. The `batch_multiplier` is a multiplicative factor that increases the number of mini-batches sampled per epoch, and so controls how often epoch statistics and log output are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b96f8665-c6d6-4064-88fc-36c166dc28fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "batch_multiplier = 10\n",
    "\n",
    "train_loader = jdas.init_dataloader(train_data, batch_size, batch_multiplier)\n",
    "val_loader = jdas.init_dataloader(val_data, batch_size, batch_multiplier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6861923-b261-4974-82af-665d50229e34",
   "metadata": {},
   "source": [
    "We can inspect a mini-batch sample by calling `__getitem__` (which fetches a mini-batch), and selecting one sample (`n`) from that batch. The output of the data loader will be\n",
    "\n",
    "1. `sample`: the randomly selected and augmented sample, which is of size 11 channels x 2048 time samples.\n",
    "2. `mask`: the mask that will be applied before the `sample` is passed to the model, which obscures one channel.\n",
    "3. `masked_sample`: the sample with the complementary mask already applied. This is the target for the model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5a2404f-3910-49c5-954c-a93b1cb7f9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2ff225379e455fbd4ae93b438a474b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 0\n",
    "\n",
    "(sample, mask), masked_sample = train_loader.__getitem__(0)\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axes = plt.subplots(nrows=3, figsize=(9, 5), constrained_layout=True, sharex=\"all\", sharey=\"all\")\n",
    "axes[0].imshow(sample[n, :, :, 0] / sample[n].std(), **imshow_kwargs)\n",
    "axes[0].set_title(\"Input sample\")\n",
    "axes[1].imshow(mask[n, :, :, 0] / mask[n].std(), **imshow_kwargs)\n",
    "axes[1].set_title(\"Input masks\")\n",
    "axes[2].imshow(masked_sample[n, :, :, 0] / masked_sample[n].std(), **imshow_kwargs)\n",
    "axes[2].set_title(\"Target sample\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ed6f89-0ea1-4f36-843e-a4ddbaa702ed",
   "metadata": {},
   "source": [
    "For completeness, this tutorial also covers how to save the retrained model and log data. This is done through TensorFlow callbacks, which are loaded into the `JDAS` class. To record the training progress (aggregated statistics on the training and validation sets after each epoch), call the `callback_tensorboard` routine with the path at which to store the log files. To save the retrained model parameters, call `callback_checkpoint` with the path to the save file (it does not need to exist yet). Note that after each epoch the model performance is evaluated on the validation set, and only the best model state is kept.\n",
    "\n",
    "Both these callbacks are entirely optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3771049e-bf0e-427d-bcac-aecb308ff606",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Callbacks \"\"\"\n",
    "\n",
    "model_name = \"retrained_example\"\n",
    "\n",
    "logdir = os.path.join(\"logs\", model_name)\n",
    "if os.path.isdir(logdir):\n",
    "    shutil.rmtree(logdir)\n",
    "    \n",
    "savefile = \"saved-model.h5\"\n",
    "savedir = os.path.join(\"save\", model_name)\n",
    "if not os.path.isdir(savedir):\n",
    "    os.makedirs(savedir)\n",
    "\n",
    "tensorboard_callback = jdas.callback_tensorboard(logdir)\n",
    "checkpoint_callback = jdas.callback_checkpoint(os.path.join(savedir, savefile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b2fc0f-48fa-48b5-80d6-2a21e01240b0",
   "metadata": {},
   "source": [
    "# Retraining the model\n",
    "\n",
    "We can now start retraining the model. Depending on how similar the new data are compared to the original data (on which the model was trained), this can take a few minutes. In this example, 10 epochs of retraining already produces acceptable results, but other data sets may require more epochs.\n",
    "\n",
    "The previously defined callbacks are passed to the training routine. In case no progress monitoring of model state saving is needed, the relevant callbacks can be omitted from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05c6bedb-9371-4bae-a21b-c4669af561c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/14 [==============================] - 86s 2s/step - loss: 0.1420 - val_loss: 0.1281\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.1237 - val_loss: 0.1209\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.1179 - val_loss: 0.1159\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.1133 - val_loss: 0.1143\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.1135 - val_loss: 0.1114\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.1093 - val_loss: 0.1100\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.1105 - val_loss: 0.1086\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.1075 - val_loss: 0.1060\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.1072 - val_loss: 0.1084\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.1079 - val_loss: 0.1068\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=train_loader, validation_data=val_loader,\n",
    "    callbacks=[tensorboard_callback, checkpoint_callback],\n",
    "    epochs=10, verbose=1, batch_size=batch_size\n",
    ")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8ab193-a096-4a7c-b676-2f3c0887c5e5",
   "metadata": {},
   "source": [
    "# Retrained model performance\n",
    "\n",
    "Lastly, we evaluate the denoising performance of the newly trained model. While we already have the retrained model in memory, we first reload best the model that was saved to disk, and then make another call to `denoise` with the new model in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de9f8702-31c6-4db0-a2f6-792aadffa537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 / 40\n",
      "Processing 5 / 40\n",
      "Processing 9 / 40\n",
      "Processing 13 / 40\n",
      "Processing 17 / 40\n",
      "Processing 21 / 40\n",
      "Processing 25 / 40\n",
      "Processing 29 / 40\n",
      "Processing 33 / 40\n",
      "Processing 37 / 40\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "model = jdas.load_model(os.path.join(savedir, savefile))\n",
    "post_train = jdas.denoise(noisy_data)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054a5a15-2344-46dd-a2b8-a55e062cc71f",
   "metadata": {},
   "source": [
    "As expected the new model performs much better in recovering the original ground truth data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "384787d6-b21c-40a4-ae18-6f843c22fbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e137142db8543f187c5af11cc88e971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_slice = slice(20_000, 30_000)\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(8, 6), constrained_layout=True, sharex=\"all\", sharey=\"all\")\n",
    "\n",
    "axes = axes.ravel()\n",
    "\n",
    "axes[0].imshow(data[:, t_slice] / data.std(), **imshow_kwargs)\n",
    "axes[0].set_title(\"Ground truth\")\n",
    "\n",
    "axes[1].imshow(noisy_data[:, t_slice] / data.std(), **imshow_kwargs)\n",
    "axes[1].set_title(\"Noisy data\")\n",
    "\n",
    "axes[2].imshow(pre_train[:, t_slice] / data.std(), **imshow_kwargs)\n",
    "axes[2].set_title(\"Reconstruction (before retraining)\")\n",
    "\n",
    "axes[3].imshow(post_train[:, t_slice] / data.std(), **imshow_kwargs)\n",
    "axes[3].set_title(\"Reconstruction (after retraining)\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bead2b5-ffb6-413d-a63b-5e288d751ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae913a07a5b348fb86fee36de5800396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 300\n",
    "\n",
    "plt.close(\"all\")\n",
    "plt.figure(figsize=(9, 6), constrained_layout=True)\n",
    "\n",
    "plt.plot(data[n, t_slice], \"k\", label=\"Ground truth\")\n",
    "plt.plot(noisy_data[n, t_slice] - 0.1, \"C0\", label=\"Noisy data\")\n",
    "plt.plot(pre_train[n, t_slice] - 0.2, \"C1\", label=\"Before retraining\")\n",
    "plt.plot(post_train[n, t_slice] - 0.3, \"C2\", label=\"After retraining\")\n",
    "\n",
    "plt.legend(loc=\"upper center\", ncol=4)\n",
    "\n",
    "plt.ylim((-0.4, 0.1))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8c8eda-907d-49d3-9665-dbd08c912e03",
   "metadata": {},
   "source": [
    "# Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d263819e-1429-47d2-91ea-fc8b058a17c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(\"logs\"):\n",
    "    shutil.rmtree(\"logs\")\n",
    "    \n",
    "if os.path.isdir(\"save\"):\n",
    "    shutil.rmtree(\"save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce792f4f-e412-4a7f-ac64-8c63ead8a8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
